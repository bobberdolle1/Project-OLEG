"""
Dailies Service for OLEG v6.0 Fortress Update.

Manages daily scheduled messages including:
- Evening summary (#dailysummary) at 20:00 Moscow time
- Evening quote (#dailyquote) at 21:00 Moscow time
- Evening stats (#dailystats) at 21:00 Moscow time

Features:
- LLM-generated chat summary
- Mood analysis
- Activity comparison with previous day
- Interesting quotes of the day
- Hot topics with links
- Toxicity thermometer

Requirements: 13.1, 13.2, 13.3, 13.4, 13.5
"""

import logging
import random
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Optional, List, Dict, Any

from sqlalchemy import select, func, and_, extract, desc
from sqlalchemy.ext.asyncio import AsyncSession

logger = logging.getLogger(__name__)


# ============================================================================
# Constants
# ============================================================================

# Minimum activity threshold for sending summary (Requirement 13.5)
MIN_ACTIVITY_FOR_SUMMARY = 1  # At least 1 message to send summary

# Quote categories for variety
QUOTE_CATEGORIES = {
    "philosophy": [
        "–ï—Å–ª–∏ –¥–æ–ª–≥–æ —Å–º–æ—Ç—Ä–µ—Ç—å –≤ –º–æ–Ω–∏—Ç–æ—Ä, –º–æ–Ω–∏—Ç–æ—Ä –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–º–æ—Ç—Ä–µ—Ç—å –≤ —Ç–µ–±—è.",
        "–ö–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–π. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî —Ç–æ–∂–µ –Ω–µ —Ç—Ä–æ–≥–∞–π.",
        "–õ—É—á—à–∏–π –∫–æ–¥ ‚Äî —Ç–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –ø—Ä–∏—à–ª–æ—Å—å –ø–∏—Å–∞—Ç—å.",
        "–ü—Ä–æ–±–ª–µ–º–∞ –Ω–µ –≤ —Ç–æ–º, —á—Ç–æ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å. –ü—Ä–æ–±–ª–µ–º–∞ –≤ —Ç–æ–º, —á—Ç–æ —Ç—ã —É–≤–µ—Ä–µ–Ω –≤ —Ç–æ–º, —á–µ–≥–æ –Ω–µ –∑–Ω–∞–µ—à—å.",
        "–û–ø—Ç–∏–º–∏—Å—Ç –≤–µ—Ä–∏—Ç, —á—Ç–æ –º—ã –∂–∏–≤—ë–º –≤ –ª—É—á—à–µ–º –∏–∑ –º–∏—Ä–æ–≤. –ü–µ—Å—Å–∏–º–∏—Å—Ç –±–æ–∏—Ç—Å—è, —á—Ç–æ —Ç–∞–∫ –æ–Ω–æ –∏ –µ—Å—Ç—å.",
        "–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –Ω–∞—Å—Ç–æ—è—â–∞—è –æ—à–∏–±–∫–∞ ‚Äî —Ç–∞, –∏–∑ –∫–æ—Ç–æ—Ä–æ–π –º—ã –Ω–∏—á–µ–≥–æ –Ω–µ –∏–∑–≤–ª–µ–∫–ª–∏.",
        "–°–ª–æ–∂–Ω–æ—Å—Ç—å ‚Äî –≤—Ä–∞–≥ –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏.",
        "–ü—Ä–æ—Å—Ç–æ—Ç–∞ ‚Äî —ç—Ç–æ –Ω–µ –∫–æ–≥–¥–∞ –Ω–µ—á–µ–≥–æ –¥–æ–±–∞–≤–∏—Ç—å, –∞ –∫–æ–≥–¥–∞ –Ω–µ—á–µ–≥–æ —É–±—Ä–∞—Ç—å.",
    ],
    "it_wisdom": [
        "–í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –∑–Ω–∞—á–∏—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü–æ—á–µ–º—É ‚Äî –≤–æ–ø—Ä–æ—Å —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π.",
        "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–∞–∫ —Å–µ–∫—Å: –∫–æ–≥–¥–∞ —Ö–æ—Ä–æ—à–∞—è ‚Äî –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–∞—è, –∫–æ–≥–¥–∞ –ø–ª–æ—Ö–∞—è ‚Äî –ª—É—á—à–µ, —á–µ–º –Ω–∏—á–µ–≥–æ.",
        "–ü–µ—Ä–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ –æ—Ç–ª–∞–¥–∫–∏: —ç—Ç–æ –Ω–µ –±–∞–≥, —ç—Ç–æ —Ñ–∏—á–∞. –í—Ç–æ—Ä–æ–µ –ø—Ä–∞–≤–∏–ª–æ: —Å–º. –ø–µ—Ä–≤–æ–µ.",
        "Legacy –∫–æ–¥ ‚Äî —ç—Ç–æ –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–Ω–æ—Å–∏—Ç –¥–µ–Ω—å–≥–∏.",
        "–•–æ—Ä–æ—à–∏–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç ‚Äî –ª–µ–Ω–∏–≤—ã–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç. –û–Ω –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç –≤—Å—ë.",
        "git push --force ‚Äî –∏ –ø—É—Å—Ç—å –≤–µ—Å—å –º–∏—Ä –ø–æ–¥–æ–∂–¥—ë—Ç.",
        "–†–∞–±–æ—Ç–∞–µ—Ç? –ö–æ–º–º–∏—Ç—å. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç? –¢–æ–∂–µ –∫–æ–º–º–∏—Ç—å, –Ω–æ —Å –ø—Ä–∏–ø–∏—Å–∫–æ–π WIP.",
        "–õ—É—á—à–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è ‚Äî —É–¥–∞–ª–∏—Ç—å –∫–æ–¥.",
        "–õ—é–±–∞—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–∂–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–≥. –õ—é–±–∞—è –ø—Ä–æ—Å—Ç–∞—è ‚Äî –¥–≤–∞.",
        "–ö–æ–¥ —Ä–µ–≤—å—é: –∏—Å–∫—É—Å—Å—Ç–≤–æ –≤–µ–∂–ª–∏–≤–æ —Å–∫–∞–∑–∞—Ç—å '–∫–∞–∫–æ–≥–æ —Ö—Ä–µ–Ω–∞'.",
    ],
    "life": [
        "–ù–µ –≤—Å–µ, –∫—Ç–æ –±—Ä–æ–¥–∏—Ç, –ø–æ—Ç–µ—Ä—è–ª–∏—Å—å. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∏—Ä—É—é—Ç.",
        "–ü–ª–∞–Ω ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –≤–µ—â–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–π–¥—É—Ç –Ω–µ —Ç–∞–∫.",
        "–î–µ–¥–ª–∞–π–Ω ‚Äî –ª—É—á—à–∞—è –º–æ—Ç–∏–≤–∞—Ü–∏—è. –û—Å–æ–±–µ–Ω–Ω–æ –≤—á–µ—Ä–∞—à–Ω–∏–π.",
        "–ö–æ—Ñ–µ –Ω–µ —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã, –Ω–æ –∏ —á–∞–π –Ω–µ —Ä–µ—à–∞–µ—Ç.",
        "–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–±—ä—è—Å–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç–æ ‚Äî –∑–Ω–∞—á–∏—Ç —Å–∞–º –Ω–µ –ø–æ–Ω—è–ª.",
        "–û–ø—ã—Ç ‚Äî —ç—Ç–æ –∫–æ–≥–¥–∞ –≤–º–µ—Å—Ç–æ –Ω–æ–≤—ã—Ö –æ—à–∏–±–æ–∫ –¥–µ–ª–∞–µ—à—å —Å—Ç–∞—Ä—ã–µ, –Ω–æ –±—ã—Å—Ç—Ä–µ–µ.",
        "–ü–µ—Ä—Ñ–µ–∫—Ü–∏–æ–Ω–∏–∑–º ‚Äî —ç—Ç–æ –ø—Ä–æ–∫—Ä–∞—Å—Ç–∏–Ω–∞—Ü–∏—è –≤ –∫—Ä–∞—Å–∏–≤–æ–π –æ–±—ë—Ä—Ç–∫–µ.",
        "–ò–Ω–æ–≥–¥–∞ –ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ ‚Äî –ø–æ–π—Ç–∏ –ø–æ—Å–ø–∞—Ç—å.",
        "–°–µ–≥–æ–¥–Ω—è –Ω–µ —Ç–æ—Ç –¥–µ–Ω—å, –∫–æ–≥–¥–∞ —è –±—É–¥—É —Ä–∞–∑–±–∏—Ä–∞—Ç—å—Å—è —Å —ç—Ç–∏–º. –ó–∞–≤—Ç—Ä–∞ —Ç–æ–∂–µ.",
    ],
    "motivation": [
        "–°–¥–µ–ª–∞–π –∏–ª–∏ –Ω–µ —Å–¥–µ–ª–∞–π. –ü—Ä–æ–±–æ–≤–∞—Ç—å ‚Äî —ç—Ç–æ –¥–ª—è —Å–ª–∞–±–∞–∫–æ–≤.",
        "–ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç –∫–æ–≥–¥–∞-—Ç–æ –±—ã–ª –Ω–æ–≤–∏—á–∫–æ–º, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Å–¥–∞–ª—Å—è.",
        "–ú–∞–ª–µ–Ω—å–∫–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å ‚Äî —Ç–æ–∂–µ –ø—Ä–æ–≥—Ä–µ—Å—Å.",
        "–ù–µ —Å—Ä–∞–≤–Ω–∏–≤–∞–π —Å–≤–æ–π –ø–µ—Ä–≤—ã–π —à–∞–≥ —Å —á—å–∏–º-—Ç–æ —Å–æ—Ç—ã–º.",
        "–û—à–∏–±–∫–∏ ‚Äî —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏.",
        "–ù–∞—á–Ω–∏. –û—Å—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–∏—Ç—Å—è.",
        "–õ—É—á—à–µ —Å–¥–µ–ª–∞—Ç—å –Ω–∞ 80% —Å–µ–≥–æ–¥–Ω—è, —á–µ–º –Ω–∞ 100% –Ω–∏–∫–æ–≥–¥–∞.",
        "–£—Å—Ç–∞–ª–æ—Å—Ç—å ‚Äî –≤—Ä–µ–º–µ–Ω–Ω–∞—è. –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π.",
    ],
    "absurd": [
        "–ï—Å–ª–∏ –∫–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞ ‚Äî –ø—Ä–æ–≤–µ—Ä—å, —Ç–æ—Ç –ª–∏ —Ñ–∞–π–ª —Ç—ã –∑–∞–ø—É—Å—Ç–∏–ª.",
        "–í—Å–µ–ª–µ–Ω–Ω–∞—è —Å—Ç—Ä–µ–º–∏—Ç—Å—è –∫ —Ö–∞–æ—Å—É. –¢–≤–æ–π –∫–æ–¥ ‚Äî —á–∞—Å—Ç—å –≤—Å–µ–ª–µ–Ω–Ω–æ–π.",
        "–ë–∞–≥–∏ –Ω–µ –∏—Å—á–µ–∑–∞—é—Ç. –û–Ω–∏ –º–∏–≥—Ä–∏—Ä—É—é—Ç.",
        "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ ‚Äî —ç—Ç–æ –ø—è—Ç–Ω–∏—Ü–∞ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –≤—Å–µ–ª–µ–Ω–Ω–æ–π.",
        "–ö—Ç–æ –ø–æ–Ω—è–ª –∂–∏–∑–Ω—å, —Ç–æ—Ç –Ω–µ —Å–ø–µ—à–∏—Ç.",
        "–ò–Ω–æ–≥–¥–∞ —Ç–∏—à–∏–Ω–∞ ‚Äî –ª—É—á—à–∏–π –æ—Ç–≤–µ—Ç. –û—Å–æ–±–µ–Ω–Ω–æ –≤ —á–∞—Ç–µ –≤ 3 –Ω–æ—á–∏.",
        "–í—Å—ë –≤—Ä–µ–º–µ–Ω–Ω–æ. –ö—Ä–æ–º–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.",
        "–ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –≤—ã–≥–ª—è–¥–∏—Ç –≥–ª—É–ø–æ, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî —ç—Ç–æ –Ω–µ –≥–ª—É–ø–æ. –≠—Ç–æ legacy.",
    ],
    "oleg_style": [
        "–•—É–π —Å –Ω–∏–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –ª–∞–¥–Ω–æ.",
        "–ù–µ –±–∞–≥, –∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ.",
        "–°–µ–≥–æ–¥–Ω—è —è –¥–æ–±—Ä—ã–π. –ó–∞–≤—Ç—Ä–∞ ‚Äî –ø–æ—Å–º–æ—Ç—Ä–∏–º.",
        "–ï—Å–ª–∏ —Ç—ã —ç—Ç–æ —á–∏—Ç–∞–µ—à—å ‚Äî –∑–Ω–∞—á–∏—Ç –µ—â—ë –Ω–µ –≤—Å—ë –ø–æ—Ç–µ—Ä—è–Ω–æ.",
        "–ì–ª–∞–≤–Ω–æ–µ ‚Äî –Ω–µ –ø–∞–Ω–∏–∫–æ–≤–∞—Ç—å. –ù—É, –∏–ª–∏ –ø–∞–Ω–∏–∫–æ–≤–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.",
        "–ë—ã–ª–æ —Å–ª–æ–∂–Ω–æ, —Å—Ç–∞–ª–æ –ø—Ä–æ—Å—Ç–æ. –®—É—á—É, –≤—Å—ë –µ—â—ë —Å–ª–æ–∂–Ω–æ.",
        "–¢—ã —Å–ø—Ä–∞–≤–∏—à—å—Å—è. –ò–ª–∏ –Ω–µ—Ç. –ù–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ç–æ–∏—Ç.",
        "–ñ–∏–∑–Ω—å –∫–æ—Ä–æ—Ç–∫–∞. –ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω—ã–π –∫–æ–¥.",
        "–û—Ç–¥—ã—Ö–∞–π, –ø–æ–∫–∞ –º–æ–∂–µ—à—å. –î–µ–¥–ª–∞–π–Ω—ã –≤–µ—á–Ω—ã.",
    ],
}

# Flattened list for backward compatibility
DEFAULT_WISDOM_QUOTES = [
    quote for quotes in QUOTE_CATEGORIES.values() for quote in quotes
]


# ============================================================================
# Data Classes
# ============================================================================

@dataclass
class DailiesConfig:
    """
    Configuration for daily messages per chat.
    
    Attributes:
        chat_id: Telegram chat ID
        summary_enabled: Whether morning summary is enabled
        quote_enabled: Whether evening quote is enabled
        stats_enabled: Whether evening stats are enabled
        summary_time_hour: Hour for summary (Moscow time)
        quote_time_hour: Hour for quote/stats (Moscow time)
    """
    chat_id: int
    summary_enabled: bool = True
    quote_enabled: bool = True
    stats_enabled: bool = True
    summary_time_hour: int = 20  # 20:00 Moscow (evening summary)
    quote_time_hour: int = 21   # 21:00 Moscow (Requirement 13.2, 13.3)


@dataclass
class DailySummary:
    """
    Daily summary data structure.
    
    Attributes:
        chat_id: Telegram chat ID
        date: Date of the summary
        message_count: Total messages yesterday
        active_users: Number of active users
        new_members: Number of new members
        moderation_actions: Count of moderation actions
        top_messages: List of top messages (by reactions)
        has_activity: Whether there was any activity
        toxicity_score: Average toxicity score (0-100)
        toxicity_incidents: Number of toxicity incidents
        hot_topics: List of hot topics with message links
        peak_hour: Hour with most activity
        top_chatters: List of most active users
        # Enhanced fields
        llm_summary: LLM-generated summary of discussions
        mood_score: Overall chat mood (0-100, 50=neutral)
        mood_label: Mood description
        interesting_quotes: Notable/funny messages
        activity_change: Percentage change vs previous day
        prev_message_count: Previous day message count for comparison
    """
    chat_id: int
    date: datetime
    message_count: int = 0
    active_users: int = 0
    new_members: int = 0
    moderation_actions: int = 0
    top_messages: List[Dict[str, Any]] = field(default_factory=list)
    has_activity: bool = False
    # Toxicity & topics
    toxicity_score: float = 0.0
    toxicity_incidents: int = 0
    hot_topics: List[Dict[str, Any]] = field(default_factory=list)
    peak_hour: Optional[int] = None
    top_chatters: List[Dict[str, Any]] = field(default_factory=list)
    # Enhanced fields
    llm_summary: Optional[str] = None
    mood_score: float = 50.0
    mood_label: str = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
    interesting_quotes: List[Dict[str, Any]] = field(default_factory=list)
    activity_change: Optional[float] = None
    prev_message_count: int = 0


@dataclass
class DailyQuote:
    """
    Daily quote data structure.
    
    Attributes:
        text: Quote text
        author: Quote author (if from Golden Fund)
        is_from_golden_fund: Whether quote is from Golden Fund
        sticker_file_id: Sticker file ID if available
    """
    text: str
    author: Optional[str] = None
    is_from_golden_fund: bool = False
    sticker_file_id: Optional[str] = None


@dataclass
class DailyStats:
    """
    Daily game statistics data structure.
    
    Attributes:
        chat_id: Telegram chat ID
        date: Date of the stats
        top_growers: List of top growers (username, growth)
        top_losers: List of top losers (username, loss)
        tournament_standings: Current tournament standings
        chart_data: PNG chart data
    """
    chat_id: int
    date: datetime
    top_growers: List[Dict[str, Any]] = field(default_factory=list)
    top_losers: List[Dict[str, Any]] = field(default_factory=list)
    tournament_standings: List[Dict[str, Any]] = field(default_factory=list)
    chart_data: Optional[bytes] = None


# ============================================================================
# Dailies Service
# ============================================================================

class DailiesService:
    """
    Service for managing daily scheduled messages.
    
    Features:
    - Morning summary at 09:00 Moscow (Requirement 13.1)
    - Evening quote at 21:00 Moscow (Requirement 13.2)
    - Evening stats at 21:00 Moscow (Requirement 13.3)
    - Chat-specific settings (Requirement 13.4)
    - Skip summary on no activity (Requirement 13.5)
    
    Properties:
    - Property 33: Daily message respect settings
    - Property 34: Skip summary on no activity
    """
    
    def __init__(self):
        """Initialize DailiesService."""
        self._golden_fund_service = None
    
    @property
    def golden_fund_service(self):
        """Lazy load golden fund service to avoid circular imports."""
        if self._golden_fund_service is None:
            try:
                from app.services.golden_fund import golden_fund_service
                self._golden_fund_service = golden_fund_service
            except Exception as e:
                logger.warning(f"Failed to load golden fund service: {e}")
        return self._golden_fund_service
    
    # =========================================================================
    # Configuration Methods
    # =========================================================================
    
    async def get_config(
        self,
        chat_id: int,
        session: Optional[AsyncSession] = None
    ) -> DailiesConfig:
        """
        Get dailies configuration for a chat.
        
        Property 33: Daily message respect settings
        *For any* chat with specific daily message types disabled,
        those messages SHALL NOT be sent.
        
        Requirement 13.4: WHEN sending daily messages THEN the Dailies
        System SHALL respect chat-specific settings for enabled/disabled
        daily messages.
        
        Args:
            chat_id: Telegram chat ID
            session: Optional database session
            
        Returns:
            DailiesConfig for the chat
        """
        from app.database.models import DailiesConfig as DailiesConfigModel
        from app.database.session import get_session
        
        close_session = False
        if session is None:
            async_session = get_session()
            session = async_session()
            close_session = True
        
        try:
            # Get dailies config from database
            result = await session.execute(
                select(DailiesConfigModel).filter_by(chat_id=chat_id)
            )
            db_config = result.scalar_one_or_none()
            
            if db_config is None:
                # Return default config for chats without explicit settings
                return DailiesConfig(chat_id=chat_id)
            
            # Map database model to dataclass
            return DailiesConfig(
                chat_id=chat_id,
                summary_enabled=db_config.summary_enabled,
                quote_enabled=db_config.quote_enabled,
                stats_enabled=db_config.stats_enabled,
                summary_time_hour=db_config.summary_time_hour,
                quote_time_hour=db_config.quote_time_hour,
            )
            
        except Exception as e:
            logger.warning(f"Failed to get dailies config for chat {chat_id}: {e}")
            # Return default config on error
            return DailiesConfig(chat_id=chat_id)
            
        finally:
            if close_session:
                await session.close()
    
    async def update_config(
        self,
        chat_id: int,
        summary_enabled: Optional[bool] = None,
        quote_enabled: Optional[bool] = None,
        stats_enabled: Optional[bool] = None,
        session: Optional[AsyncSession] = None
    ) -> DailiesConfig:
        """
        Update dailies configuration for a chat.
        
        Requirement 13.4: Respect chat-specific settings for enabled/disabled
        daily messages.
        
        Args:
            chat_id: Telegram chat ID
            summary_enabled: Enable/disable morning summary
            quote_enabled: Enable/disable evening quote
            stats_enabled: Enable/disable evening stats
            session: Optional database session
            
        Returns:
            Updated DailiesConfig
        """
        from app.database.models import DailiesConfig as DailiesConfigModel
        from app.database.session import get_session
        
        close_session = False
        if session is None:
            async_session = get_session()
            session = async_session()
            close_session = True
        
        try:
            # Get or create config
            result = await session.execute(
                select(DailiesConfigModel).filter_by(chat_id=chat_id)
            )
            db_config = result.scalar_one_or_none()
            
            if db_config is None:
                # Create new config
                db_config = DailiesConfigModel(chat_id=chat_id)
                session.add(db_config)
            
            # Update fields if provided
            if summary_enabled is not None:
                db_config.summary_enabled = summary_enabled
            if quote_enabled is not None:
                db_config.quote_enabled = quote_enabled
            if stats_enabled is not None:
                db_config.stats_enabled = stats_enabled
            
            await session.commit()
            
            # Return updated config as dataclass
            return DailiesConfig(
                chat_id=chat_id,
                summary_enabled=db_config.summary_enabled,
                quote_enabled=db_config.quote_enabled,
                stats_enabled=db_config.stats_enabled,
                summary_time_hour=db_config.summary_time_hour,
                quote_time_hour=db_config.quote_time_hour,
            )
            
        except Exception as e:
            logger.error(f"Failed to update dailies config for chat {chat_id}: {e}")
            if session:
                await session.rollback()
            # Return current config on error
            return await self.get_config(chat_id, session)
            
        finally:
            if close_session:
                await session.close()
    
    def should_send_message(
        self,
        config: DailiesConfig,
        message_type: str
    ) -> bool:
        """
        Check if a specific daily message type should be sent.
        
        Property 33: Daily message respect settings
        *For any* chat with specific daily message types disabled,
        those messages SHALL NOT be sent.
        
        Args:
            config: Chat's dailies configuration
            message_type: Type of message ('summary', 'quote', 'stats')
            
        Returns:
            True if message should be sent, False otherwise
        """
        if message_type == 'summary':
            return config.summary_enabled
        elif message_type == 'quote':
            return config.quote_enabled
        elif message_type == 'stats':
            return config.stats_enabled
        return False
    
    # =========================================================================
    # Summary Generation (Requirement 13.1)
    # =========================================================================
    
    async def generate_summary(
        self,
        chat_id: int,
        session: Optional[AsyncSession] = None,
        for_today: bool = True
    ) -> Optional[DailySummary]:
        """
        Generate daily summary for a chat.
        
        Args:
            chat_id: Telegram chat ID
            session: Optional database session
            for_today: If True, summarizes today so far. If False, summarizes yesterday.
            
        Returns:
            DailySummary if there was activity, None otherwise
        """
        from app.database.models import MessageLog, User
        from app.database.session import get_session
        from app.utils import utc_now
        
        close_session = False
        if session is None:
            async_session = get_session()
            session = async_session()
            close_session = True
        
        try:
            now = utc_now()
            if for_today:
                # Today so far (from 00:00 UTC)
                start_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
                end_time = now
            else:
                # Full yesterday
                start_time = (now - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
                end_time = now.replace(hour=0, minute=0, second=0, microsecond=0)
            
            # Count messages
            message_count_result = await session.execute(
                select(func.count(MessageLog.id)).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time
                )
            )
            message_count = message_count_result.scalar() or 0
            
            # Property 34: Skip if no activity
            if message_count < MIN_ACTIVITY_FOR_SUMMARY:
                logger.debug(f"Skipping summary for chat {chat_id}: no activity")
                return DailySummary(
                    chat_id=chat_id,
                    date=start_time,
                    message_count=0,
                    has_activity=False
                )
            
            # Count active users
            active_users_result = await session.execute(
                select(func.count(func.distinct(MessageLog.user_id))).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time
                )
            )
            active_users = active_users_result.scalar() or 0
            
            # Count new members (users created in range)
            new_members_result = await session.execute(
                select(func.count(User.id)).filter(
                    User.created_at >= start_time,
                    User.created_at < end_time
                )
            )
            new_members = new_members_result.scalar() or 0
            
            moderation_actions = 0
            
            # Toxicity & incidents
            toxicity_score, toxicity_incidents = await self._calculate_toxicity_from_messages(
                chat_id, start_time, end_time, session
            )
            
            # Peak activity hour
            peak_hour_result = await session.execute(
                select(
                    extract('hour', MessageLog.created_at).label('hour'),
                    func.count(MessageLog.id).label('cnt')
                ).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time
                ).group_by(
                    extract('hour', MessageLog.created_at)
                ).order_by(
                    desc('cnt')
                ).limit(1)
            )
            peak_row = peak_hour_result.first()
            peak_hour = int(peak_row[0]) if peak_row else None
            
            # Top chatters
            top_chatters_result = await session.execute(
                select(
                    MessageLog.username,
                    MessageLog.user_id,
                    func.count(MessageLog.id).label('msg_count')
                ).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time
                ).group_by(
                    MessageLog.user_id, MessageLog.username
                ).order_by(
                    desc('msg_count')
                ).limit(5)
            )
            top_chatters = [
                {
                    "username": row.username or f"User {row.user_id}",
                    "user_id": row.user_id,
                    "count": row.msg_count
                }
                for row in top_chatters_result.all()
            ]
            
            # Hot topics
            hot_topics = await self._extract_hot_topics(
                chat_id, start_time, end_time, session
            )
            
            # Activity comparison with previous period
            prev_start = start_time - (end_time - start_time)
            prev_count_result = await session.execute(
                select(func.count(MessageLog.id)).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= prev_start,
                    MessageLog.created_at < start_time
                )
            )
            prev_message_count = prev_count_result.scalar() or 0
            
            activity_change = None
            if prev_message_count > 0:
                activity_change = ((message_count - prev_message_count) / prev_message_count) * 100
            
            # Interesting quotes
            interesting_quotes = await self._extract_interesting_quotes(
                chat_id, start_time, end_time, session
            )
            
            # Mood analysis
            mood_score, mood_label = await self._analyze_chat_mood(
                chat_id, start_time, end_time, session, toxicity_score
            )
            
            # LLM Summary
            llm_summary = await self._generate_llm_summary(
                chat_id, start_time, end_time, session,
                message_count, hot_topics, top_chatters
            )
            
            return DailySummary(
                chat_id=chat_id,
                date=start_time,
                message_count=message_count,
                active_users=active_users,
                new_members=new_members,
                moderation_actions=moderation_actions,
                has_activity=True,
                toxicity_score=toxicity_score,
                toxicity_incidents=toxicity_incidents,
                hot_topics=hot_topics,
                peak_hour=peak_hour,
                top_chatters=top_chatters,
                llm_summary=llm_summary,
                mood_score=mood_score,
                mood_label=mood_label,
                interesting_quotes=interesting_quotes,
                activity_change=activity_change,
                prev_message_count=prev_message_count,
            )
            
        except Exception as e:
            logger.error(f"Failed to generate summary for chat {chat_id}: {e}")
            return None
            
        finally:
            if close_session:
                await session.close()
    
    async def _extract_hot_topics(
        self,
        chat_id: int,
        start_time: datetime,
        end_time: datetime,
        session: AsyncSession
    ) -> List[Dict[str, Any]]:
        """
        Extract hot topics from messages using LLM clustering.
        
        Uses LLM to identify and group discussion topics, then finds
        representative messages for each topic.
        
        Args:
            chat_id: Telegram chat ID
            start_time: Start of time range
            end_time: End of time range
            session: Database session
            
        Returns:
            List of hot topics with message links and counts
        """
        from app.database.models import MessageLog
        import re
        import json
        
        try:
            # Get messages with text
            messages_result = await session.execute(
                select(MessageLog).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time,
                    MessageLog.text.isnot(None)
                ).order_by(MessageLog.created_at.desc()).limit(500)
            )
            messages = messages_result.scalars().all()
            
            if not messages or len(messages) < 10:
                return []
            
            # Prepare messages sample for LLM
            messages_sample = []
            for msg in messages[:200]:
                if msg.text and len(msg.text) > 5:
                    messages_sample.append({
                        "id": msg.message_id,
                        "text": msg.text[:200],
                        "user": msg.username or "user"
                    })
            
            if len(messages_sample) < 10:
                return []
            
            # Use LLM to extract topics
            try:
                from app.services.ollama_client import _ollama_chat
                
                sample_text = "\n".join([
                    f"[{m['id']}] {m['user']}: {m['text']}" 
                    for m in messages_sample[:100]
                ])
                
                prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏—è —á–∞—Ç–∞ –∏ –≤—ã–¥–µ–ª–∏ 5-8 –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º –æ–±—Å—É–∂–¥–µ–Ω–∏—è.

–°–æ–æ–±—â–µ–Ω–∏—è:
{sample_text}

–î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã —É–∫–∞–∂–∏:
1. –ö—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã (2-4 —Å–ª–æ–≤–∞) —Å —ç–º–æ–¥–∑–∏
2. –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ —Ç–µ–º–µ
3. ID –æ–¥–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞

–û—Ç–≤–µ—Ç—å –°–¢–†–û–ì–û –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
[
  {{"topic": "üòÇ –°–º–µ—à–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã", "count": 45, "msg_id": 12345}},
  {{"topic": "üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã", "count": 30, "msg_id": 12346}}
]

–¢–æ–ª—å–∫–æ JSON, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π!"""

                llm_messages = [
                    {"role": "system", "content": "–¢—ã –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å —á–∞—Ç—ã –∏ –≤—ã–¥–µ–ª—è–µ—à—å —Ç–µ–º—ã. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON."},
                    {"role": "user", "content": prompt}
                ]
                
                response = await _ollama_chat(llm_messages, temperature=0.3)
                
                # Parse JSON response
                # Try to extract JSON from response
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    topics_data = json.loads(json_match.group())
                else:
                    topics_data = json.loads(response)
                
                hot_topics = []
                for item in topics_data[:8]:
                    topic = {
                        "keyword": item.get("topic", "–¢–µ–º–∞"),
                        "mentions": item.get("count", 10),
                        "message_id": item.get("msg_id"),
                        "chat_id": chat_id
                    }
                    hot_topics.append(topic)
                
                return hot_topics
                
            except Exception as llm_error:
                logger.debug(f"LLM topic extraction failed: {llm_error}, falling back to keywords")
                # Fallback to keyword extraction
                return await self._extract_hot_topics_fallback(messages, chat_id)
            
        except Exception as e:
            logger.warning(f"Failed to extract hot topics: {e}")
            return []
    
    async def _extract_hot_topics_fallback(
        self,
        messages: List,
        chat_id: int
    ) -> List[Dict[str, Any]]:
        """Fallback keyword-based topic extraction."""
        from collections import Counter
        import re
        
        stop_words = {
            '—ç—Ç–æ', '–∫–∞–∫', '—á—Ç–æ', '–¥–ª—è', '–≤—Å–µ', '–æ–Ω–∏', '–µ–≥–æ', '–æ–Ω–∞', '—Ç–∞–∫',
            '—É–∂–µ', '–∏–ª–∏', '–µ—Å–ª–∏', '–µ—Å—Ç—å', '–±—ã–ª–æ', '–±—ã—Ç—å', '–±—ã–ª', '–±—ã–ª–∞',
            '–±—ã–ª–∏', '–±—É–¥–µ—Ç', '–±—É–¥—É—Ç', '–æ—á–µ–Ω—å', '–ø—Ä–æ—Å—Ç–æ', '–º–æ–∂–Ω–æ', '–Ω—É–∂–Ω–æ',
            '—Ç–∞–º', '—Ç—É—Ç', '–∑–¥–µ—Å—å', '–∫–æ–≥–¥–∞', '–ø–æ—Ç–æ–º', '—Ç–æ–∂–µ', '—Ç–æ–ª—å–∫–æ',
            '–µ—â—ë', '–µ—â–µ', '–≤–æ—Ç', '—á—Ç–æ–±—ã', '—ç—Ç–æ—Ç', '—ç—Ç–æ–≥–æ', '—ç—Ç–æ–º', '—ç—Ç–æ–π',
            '–Ω–∞–¥–æ', '–º–µ–Ω—è', '—Ç–µ–±—è', '–Ω–∞—Ö—É–π', '—Å—É–∫–∞', '–±–ª—è—Ç—å', '—Ö—É–π',
        }
        
        word_messages = {}
        word_counts = Counter()
        
        for msg in messages:
            if not msg.text:
                continue
            words = re.findall(r'[–∞-—è—ëa-z]{4,}', msg.text.lower())
            seen = set()
            for word in words:
                if word not in stop_words and word not in seen:
                    seen.add(word)
                    word_counts[word] += 1
                    if word not in word_messages:
                        word_messages[word] = msg
        
        hot_topics = []
        for word, count in word_counts.most_common(5):
            if count < 5:
                continue
            msg = word_messages.get(word)
            hot_topics.append({
                "keyword": word.capitalize(),
                "mentions": count,
                "message_id": msg.message_id if msg else None,
                "chat_id": chat_id
            })
        
        return hot_topics
    
    async def _extract_interesting_quotes(
        self,
        chat_id: int,
        start_time: datetime,
        end_time: datetime,
        session: AsyncSession
    ) -> List[Dict[str, Any]]:
        """
        Extract interesting/funny messages from the day.
        
        Looks for messages with certain patterns that indicate humor or interest.
        """
        from app.database.models import MessageLog
        
        try:
            # Get messages with text
            messages_result = await session.execute(
                select(MessageLog).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time,
                    MessageLog.text.isnot(None)
                ).order_by(MessageLog.created_at.desc()).limit(300)
            )
            messages = messages_result.scalars().all()
            
            if not messages:
                return []
            
            interesting = []
            
            for msg in messages:
                if not msg.text or len(msg.text) < 15 or len(msg.text) > 200:
                    continue
                
                text_lower = msg.text.lower()
                score = 0
                
                # Humor indicators
                if any(x in text_lower for x in ['üòÇ', 'ü§£', '—Ö–∞—Ö–∞—Ö', '–ª–æ–ª', '–∞—Ö–∞—Ö', '—Ä–∂—É']):
                    score += 2
                if any(x in text_lower for x in ['–±–ª—è—Ç—å', '–ø–∏–∑–¥–µ—Ü', '–µ–±–∞—Ç—å', '–æ—Ö—É–µ']):
                    score += 1  # Expressive
                if '?' in msg.text and '!' in msg.text:
                    score += 1  # Emotional
                if msg.text.count('!') >= 2:
                    score += 1
                # Avoid boring messages
                if any(x in text_lower for x in ['–ø—Ä–∏–≤–µ—Ç', '–ø–æ–∫–∞', '—Å–ø–∞—Å–∏–±–æ', '–æ–∫', '–¥–∞', '–Ω–µ—Ç']):
                    score -= 2
                if len(msg.text) < 30:
                    score -= 1
                
                if score >= 2:
                    interesting.append({
                        "text": msg.text[:150] + ("..." if len(msg.text) > 150 else ""),
                        "username": msg.username or f"User {msg.user_id}",
                        "message_id": msg.message_id,
                        "score": score
                    })
            
            # Sort by score and take top 3
            interesting.sort(key=lambda x: x["score"], reverse=True)
            return interesting[:3]
            
        except Exception as e:
            logger.warning(f"Failed to extract interesting quotes: {e}")
            return []
    
    async def _calculate_toxicity_from_messages(
        self,
        chat_id: int,
        start_time: datetime,
        end_time: datetime,
        session: AsyncSession
    ) -> tuple[float, int]:
        """
        Calculate toxicity score from message content as fallback.
        
        Returns:
            (toxicity_score 0-100, incident_count)
        """
        from app.database.models import MessageLog
        import re
        
        try:
            messages_result = await session.execute(
                select(MessageLog.text).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time,
                    MessageLog.text.isnot(None)
                ).limit(500)
            )
            texts = [row[0] for row in messages_result.all() if row[0]]
            
            if not texts:
                return 0.0, 0
            
            # Toxic patterns (Russian mat and aggressive words)
            toxic_patterns = [
                r'\b[—Öx][—Éy][–π–∏–µ—è—é—ëijey]\w*',
                r'\b[–øp][–∏i–µ][–∑z][–¥d]\w*',
                r'\b[–±b][–ªl][—èa]\w*',
                r'\b[–µe][–±b]\w*',
                r'\b[—Åc][—Éy][–∫k]\w*',
                r'\b[–ºm][—Éy][–¥d][–∞a]\w*',
                r'\bf+u+c+k+\w*',
                r'\bs+h+i+t+\w*',
                r'\b(—É–±—å—é|—Å–¥–æ—Ö–Ω–∏|—É—Ä–æ–¥|–¥–µ–±–∏–ª|–∏–¥–∏–æ—Ç|–∫—Ä–µ—Ç–∏–Ω|–¥–∞—É–Ω|–ª–æ—Ö)\b',
            ]
            
            toxic_count = 0
            incident_messages = 0
            
            for text in texts:
                text_lower = text.lower()
                is_toxic = False
                for pattern in toxic_patterns:
                    if re.search(pattern, text_lower, re.IGNORECASE):
                        toxic_count += 1
                        is_toxic = True
                        break
                if is_toxic:
                    incident_messages += 1
            
            # Calculate score (0-100)
            total = len(texts)
            toxicity_ratio = toxic_count / total if total > 0 else 0
            toxicity_score = min(100, toxicity_ratio * 100)
            
            return toxicity_score, incident_messages
            
        except Exception as e:
            logger.warning(f"Failed to calculate toxicity from messages: {e}")
            return 0.0, 0

    async def _analyze_chat_mood(
        self,
        chat_id: int,
        start_time: datetime,
        end_time: datetime,
        session: AsyncSession,
        toxicity_score: float
    ) -> tuple[float, str]:
        """
        Analyze overall chat mood based on message patterns.
        
        Returns:
            (mood_score, mood_label) where score is 0-100 (50=neutral)
        """
        from app.database.models import MessageLog
        
        try:
            messages_result = await session.execute(
                select(MessageLog.text).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time,
                    MessageLog.text.isnot(None)
                ).limit(200)
            )
            texts = [row[0] for row in messages_result.all() if row[0]]
            
            if not texts:
                return 50.0, "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
            
            positive_count = 0
            negative_count = 0
            
            positive_markers = ['üòä', 'üòÑ', 'ü•∞', '‚ù§Ô∏è', 'üëç', 'üéâ', 'üòÅ', '–∫—Ä—É—Ç–æ', '–∫–ª–∞—Å—Å', 
                              '–æ—Ç–ª–∏—á–Ω–æ', '—Å—É–ø–µ—Ä', '—Å–ø–∞—Å–∏–±–æ', '–º–æ–ª–æ–¥–µ—Ü', '–∫—Ä–∞—Å–∞–≤–∞', '—Ç–æ–ø']
            negative_markers = ['üò¢', 'üò≠', 'üò§', 'üò°', 'üëé', 'üíî', '–ø–ª–æ—Ö–æ', '—É–∂–∞—Å', 
                              '–æ—Ç—Å—Ç–æ–π', '—Ö—É–π–Ω—è', '–ø–∏–∑–¥–µ—Ü', '–±–ª—è—Ç—å', '–¥–µ—Ä—å–º–æ']
            
            for text in texts:
                text_lower = text.lower()
                if any(m in text_lower for m in positive_markers):
                    positive_count += 1
                if any(m in text_lower for m in negative_markers):
                    negative_count += 1
            
            total = len(texts)
            positive_ratio = positive_count / total if total > 0 else 0
            negative_ratio = negative_count / total if total > 0 else 0
            
            # Calculate mood score (0-100, 50 is neutral)
            # Toxicity also affects mood negatively
            base_mood = 50 + (positive_ratio * 40) - (negative_ratio * 30) - (toxicity_score * 0.2)
            mood_score = max(0, min(100, base_mood))
            
            # Determine label
            if mood_score >= 75:
                mood_label = "–û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ! üåü"
            elif mood_score >= 60:
                mood_label = "–ü–æ–∑–∏—Ç–∏–≤–Ω–æ üòä"
            elif mood_score >= 45:
                mood_label = "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
            elif mood_score >= 30:
                mood_label = "–ù–∞–ø—Ä—è–∂—ë–Ω–Ω–æ üòê"
            else:
                mood_label = "–¢—è–∂—ë–ª—ã–π –¥–µ–Ω—å üòî"
            
            return mood_score, mood_label
            
        except Exception as e:
            logger.warning(f"Failed to analyze mood: {e}")
            return 50.0, "–ù–µ–π—Ç—Ä–∞–ª—å–Ω–æ"
    
    async def _generate_llm_summary(
        self,
        chat_id: int,
        start_time: datetime,
        end_time: datetime,
        session: AsyncSession,
        message_count: int,
        hot_topics: List[Dict[str, Any]],
        top_chatters: List[Dict[str, Any]]
    ) -> Optional[str]:
        """
        Generate LLM-based summary of chat discussions.
        """
        from app.database.models import MessageLog
        
        try:
            # Get sample of messages for context
            messages_result = await session.execute(
                select(MessageLog.text, MessageLog.username).filter(
                    MessageLog.chat_id == chat_id,
                    MessageLog.created_at >= start_time,
                    MessageLog.created_at < end_time,
                    MessageLog.text.isnot(None)
                ).order_by(func.random()).limit(100)
            )
            messages = messages_result.all()
            
            if len(messages) < 5:
                return None
            
            # Build context
            topics_str = ", ".join([t["keyword"] for t in hot_topics[:5]]) if hot_topics else "—Ä–∞–∑–Ω–æ–µ"
            chatters_str = ", ".join([c["username"] for c in top_chatters[:3]]) if top_chatters else "—É—á–∞—Å—Ç–Ω–∏–∫–∏"
            
            sample_texts = [f"{m.username}: {m.text[:150]}" for m in messages[:40] if m.text]
            messages_sample = "\n".join(sample_texts)
            
            from app.services.ollama_client import _ollama_chat
            
            prompt = f"""–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –∏ –¥–µ—Ä–∑–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –æ–±—Å—É–∂–¥–µ–Ω–∏–π –≤ —á–∞—Ç–µ –∑–∞ —Å–µ–≥–æ–¥–Ω—è.

–°–¢–ê–¢–ò–°–¢–ò–ö–ê:
- –°–æ–æ–±—â–µ–Ω–∏–π: {message_count}
- –ì–ª–∞–≤–Ω—ã–µ —Ç–µ–º—ã: {topics_str}
- –¢–æ–ø –±–æ–ª—Ç—É–Ω–æ–≤: {chatters_str}

–°–û–û–ë–©–ï–ù–ò–Ø –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{messages_sample}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –ú–∞–∫—Å–∏–º—É–º 2-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –°—Ç–∏–ª—å –û–ª–µ–≥–∞: –∏—Ä–æ–Ω–∏—á–Ω—ã–π, —à–∞—Ä—è—â–∏–π –≤ –ò–¢, –Ω–µ–º–Ω–æ–≥–æ —Ü–∏–Ω–∏—á–Ω—ã–π, –Ω–æ —Å–≤–æ–π –≤ –¥–æ—Å–∫—É
- –ù–∏–∫–∞–∫–∏—Ö "—Å–µ–≥–æ–¥–Ω—è —É—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—Å—É–∂–¥–∞–ª–∏" ‚Äî –ø–∏—à–∏ —Å—Ä–∞–∑—É —Å—É—Ç—å
- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–ª–µ–Ω–≥ (—Ç–∞—á–∫–∞, –∑–∞—Ç—ã–∫, –±–∞–∑–∞, —Å–æ—è, —á–µ–ª–∏–∫)
- –ï—Å–ª–∏ –æ–±—Å—É–∂–¥–∞–ª–∏ –ø–∏–≤–æ, –∂–µ–ª–µ–∑–æ –∏–ª–∏ –ß–µ—Ö–∏—é ‚Äî –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–ø–æ–º—è–Ω–∏ –≤ —Å–≤–æ—ë–º —Å—Ç–∏–ª–µ

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –ø–µ—Ä–µ—Å–∫–∞–∑–æ–º, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π –∏ –∫–∞–≤—ã—á–µ–∫."""

            messages_for_llm = [
                {"role": "system", "content": "–¢—ã –û–ª–µ–≥ ‚Äî –¥–µ—Ä–∑–∫–∏–π –ò–¢-—ç–∫—Å–ø–µ—Ä—Ç. –î–µ–ª–∞–µ—à—å –∫—Ä–∞—Ç–∫–∏–µ –∏ –µ–¥–∫–∏–µ –ø–µ—Ä–µ—Å–∫–∞–∑—ã —á–∞—Ç–æ–≤. –¢–≤–æ–π —é–º–æ—Ä ‚Äî –±–∞–∑–∞."},
                {"role": "user", "content": prompt}
            ]
            
            summary = await _ollama_chat(messages_for_llm, temperature=0.8)
            
            # Clean and validate
            summary = summary.strip().strip('"')
            if len(summary) < 15 or len(summary) > 500:
                return None
            
            return summary
            
        except Exception as e:
            logger.debug(f"Failed to generate LLM summary: {e}")
            return None
    
    def _get_toxicity_emoji(self, score: float) -> str:
        """Get toxicity thermometer emoji based on score."""
        if score < 20:
            return "üü¢"  # Green - very chill
        elif score < 40:
            return "üü°"  # Yellow - mild
        elif score < 60:
            return "üü†"  # Orange - warming up
        elif score < 80:
            return "üî¥"  # Red - hot
        else:
            return "üî•"  # Fire - toxic
    
    def _get_toxicity_label(self, score: float) -> str:
        """Get toxicity label based on score."""
        if score < 20:
            return "–ß–∏–ª–ª üòé"
        elif score < 40:
            return "–°–ø–æ–∫–æ–π–Ω–æ"
        elif score < 60:
            return "–ë—É—Ä–Ω–æ"
        elif score < 80:
            return "–ì–æ—Ä—è—á–æ üå∂Ô∏è"
        else:
            return "–¢–æ–∫—Å–∏—á–Ω–æ ‚ò¢Ô∏è"
    
    def should_skip_summary(self, summary: Optional[DailySummary]) -> bool:
        """
        Check if summary should be skipped due to no activity.
        
        Property 34: Skip summary on no activity
        *For any* chat with zero messages in the past 24 hours,
        the daily summary SHALL be skipped.
        
        Args:
            summary: Generated summary or None
            
        Returns:
            True if summary should be skipped, False otherwise
        """
        if summary is None:
            return True
        return not summary.has_activity
    
    def format_summary(self, summary: DailySummary) -> str:
        """
        Format daily summary for display.
        
        Enhanced evening summary with LLM insights, mood, quotes, and comparisons.
        """
        date_str = summary.date.strftime("%d.%m.%Y")
        
        lines = [
            f"üåÜ #dailysummary –∑–∞ {date_str}",
            "",
        ]
        
        # LLM Summary at the top (if available)
        if summary.llm_summary:
            lines.append(f"üìù {summary.llm_summary}")
            lines.append("")
        
        # Stats with comparison
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        lines.append("üìà –¶–ò–§–†–´ –î–ù–Ø")
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        
        # Message count with trend
        trend = ""
        if summary.activity_change is not None:
            if summary.activity_change > 10:
                trend = f" üìà +{summary.activity_change:.0f}%"
            elif summary.activity_change < -10:
                trend = f" üìâ {summary.activity_change:.0f}%"
            elif summary.activity_change != 0:
                trend = f" ‚Üí {summary.activity_change:+.0f}%"
        
        lines.append(f"üí¨ –°–æ–æ–±—â–µ–Ω–∏–π: {summary.message_count}{trend}")
        lines.append(f"üë• –ê–∫—Ç–∏–≤–Ω—ã—Ö: {summary.active_users}")
        
        if summary.peak_hour is not None:
            lines.append(f"‚è∞ –ü–∏–∫: {summary.peak_hour}:00")
        
        if summary.new_members > 0:
            lines.append(f"üÜï –ù–æ–≤–∏—á–∫–æ–≤: {summary.new_members}")
        
        # Mood & Toxicity combined
        lines.append("")
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        lines.append("üé≠ –í–ê–ô–ë –ß–ê–¢–ê")
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        
        # Mood bar
        mood_filled = int(summary.mood_score / 10)
        mood_bar = "‚ñà" * mood_filled + "‚ñë" * (10 - mood_filled)
        lines.append(f"üòä [{mood_bar}] {summary.mood_label}")
        
        # Toxicity (compact)
        toxicity_emoji = self._get_toxicity_emoji(summary.toxicity_score)
        toxicity_label = self._get_toxicity_label(summary.toxicity_score)
        lines.append(f"{toxicity_emoji} –¢–æ–∫—Å–∏—á–Ω–æ—Å—Ç—å: {summary.toxicity_score:.0f}% ‚Äî {toxicity_label}")
        
        if summary.toxicity_incidents > 0:
            lines.append(f"üö® –ò–Ω—Ü–∏–¥–µ–Ω—Ç–æ–≤: {summary.toxicity_incidents}")
        
        # Top chatters (compact)
        if summary.top_chatters:
            lines.append("")
            lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            lines.append("üèÜ –ë–û–õ–¢–£–ù–´ –î–ù–Ø")
            lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            medals = ["ü•á", "ü•à", "ü•â"]
            for i, chatter in enumerate(summary.top_chatters[:3]):
                medal = medals[i] if i < len(medals) else f"{i+1}."
                lines.append(f"{medal} {chatter['username']} ‚Äî {chatter['count']}")
        
        # Hot topics with links
        if summary.hot_topics:
            lines.append("")
            lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            lines.append("üî• –û–ë–°–£–ñ–î–ê–õ–ò")
            lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
            for topic in summary.hot_topics[:5]:
                keyword = topic['keyword']
                mentions = topic['mentions']
                msg_id = topic.get('message_id')
                
                if msg_id and summary.chat_id:
                    chat_id_str = str(abs(summary.chat_id))
                    if chat_id_str.startswith("100"):
                        chat_id_str = chat_id_str[3:]
                    link = f"https://t.me/c/{chat_id_str}/{msg_id}"
                    lines.append(f'‚Ä¢ <a href="{link}">{keyword}</a> ({mentions})')
                else:
                    lines.append(f"‚Ä¢ {keyword} ({mentions})")
        
        # Footer
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        lines.append(self._get_summary_footer())
        
        return "\n".join(lines)
    
    def _get_summary_footer(self) -> str:
        """Get contextual footer for summary."""
        footers = [
            "–•–æ—Ä–æ—à–µ–≥–æ –≤–µ—á–µ—Ä–∞! üåô",
            "–û—Ç–¥—ã—Ö–∞–π—Ç–µ! üò¥",
            "–î–æ –∑–∞–≤—Ç—Ä–∞! üëã",
            "–°–ø–æ–∫–æ–π–Ω–æ–π –Ω–æ—á–∏! üåÉ",
            "–ó–∞–≤—Ç—Ä–∞ –Ω–æ–≤—ã–π –¥–µ–Ω—å! ‚ú®",
        ]
        return random.choice(footers)
    
    # =========================================================================
    # Quote Selection (Requirement 13.2)
    # =========================================================================
    
    async def select_daily_quote(
        self,
        chat_id: Optional[int] = None,
        session: Optional[AsyncSession] = None
    ) -> DailyQuote:
        """
        Select a daily quote (from Golden Fund or LLM-generated).
        """
        roll = random.random()
        
        # 30% chance: Try Golden Fund first
        if roll < 0.3 and self.golden_fund_service:
            try:
                golden_quote = await self.golden_fund_service.get_random_golden_quote(
                    chat_id=chat_id
                )
                
                if golden_quote:
                    return DailyQuote(
                        text=golden_quote.text,
                        author=golden_quote.username,
                        is_from_golden_fund=True,
                        sticker_file_id=golden_quote.sticker_file_id
                    )
            except Exception as e:
                logger.warning(f"Failed to get golden quote: {e}")
        
        # Get active names and persona for personalization
        active_names = []
        persona = "oleg"
        
        if chat_id:
            try:
                from app.services.ollama_client import recent_active_usernames
                active_names = await recent_active_usernames(chat_id, hours=24, limit=10)
                
                # Fetch persona from BotConfig
                from app.database.models import BotConfig
                from sqlalchemy import select
                
                close_session = False
                if session is None:
                    from app.database.session import get_session
                    async_session = get_session()
                    session = async_session()
                    close_session = True
                
                result = await session.execute(
                    select(BotConfig.persona).filter_by(chat_id=chat_id)
                )
                db_persona = result.scalar_one_or_none()
                if db_persona:
                    persona = db_persona
                
                if close_session:
                    await session.close()
            except Exception as e:
                logger.warning(f"Failed to fetch context for quote: {e}")

        # 70% chance: Generate unique quote via LLM
        llm_quote = await self._generate_llm_quote(active_names, persona)
        if llm_quote:
            return DailyQuote(
                text=llm_quote,
                author="–û–ª–µ–≥",
                is_from_golden_fund=False,
                sticker_file_id=None
            )
        
        # Fallback: Pick from categorized quotes
        return self._select_category_quote()
    
    def _select_category_quote(self) -> DailyQuote:
        """
        Select a quote from predefined categories based on day/mood.
        
        Uses day of week to vary categories:
        - Monday: motivation
        - Tuesday: it_wisdom  
        - Wednesday: philosophy
        - Thursday: life
        - Friday: oleg_style
        - Saturday: absurd
        - Sunday: random category
        """
        from datetime import datetime
        
        day_categories = {
            0: "motivation",    # Monday - need motivation
            1: "it_wisdom",     # Tuesday - tech day
            2: "philosophy",    # Wednesday - mid-week thoughts
            3: "life",          # Thursday - life wisdom
            4: "oleg_style",    # Friday - Oleg mode
            5: "absurd",        # Saturday - weird stuff
            6: None,            # Sunday - random
        }
        
        weekday = datetime.now().weekday()
        category = day_categories.get(weekday)
        
        if category and category in QUOTE_CATEGORIES:
            quotes = QUOTE_CATEGORIES[category]
        else:
            # Random category on Sunday or fallback
            category = random.choice(list(QUOTE_CATEGORIES.keys()))
            quotes = QUOTE_CATEGORIES[category]
        
        quote_text = random.choice(quotes)
        
        return DailyQuote(
            text=quote_text,
            author=None,
            is_from_golden_fund=False,
            sticker_file_id=None
        )
    
    async def _generate_llm_quote(self, active_names: List[str] = None, persona: str = "oleg") -> Optional[str]:
        """
        Generate a unique daily quote using LLM based on persona.
        
        Returns:
            Generated quote text or None if generation fails
        """
        try:
            from app.services.ollama_client import _ollama_chat, get_static_system_prompt
            from datetime import datetime
            
            # Context about active users
            users_context = ""
            if active_names:
                users_context = f"–ê–∫—Ç–∏–≤–Ω—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —á–∞—Ç–∞: {', '.join(['@' + n for n in active_names])}."
            
            # Get persona-specific base instructions
            persona_base = get_static_system_prompt(persona)
            
            prompt = f"""–ü—Ä–∏–¥—É–º–∞–π –æ–¥–Ω—É –º–µ–º–Ω—É—é, –∞–±—Å—É—Ä–¥–Ω—É—é –∏–ª–∏ –∏—Ä–æ–Ω–∏—á–Ω—É—é '—Ü–∏—Ç–∞—Ç—É –¥–Ω—è' –¥–ª—è —á–∞—Ç–∞. 
{users_context}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –¢–í–û–ô –°–¢–ò–õ–¨: –ò—Å–ø–æ–ª—å–∑—É–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä –∏ –º–∞–Ω–µ—Ä—É —Ä–µ—á–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏ (—Å–º. —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∏–∂–µ).
- –¢–ï–ú–ê: –ü–æ—Å—Ç–∏—Ä–æ–Ω–∏—è, –º–µ–º—ã, –∂–∏–∑–Ω–µ–Ω–Ω—ã–π –∞–±—Å—É—Ä–¥.
- –ò–∑–±–µ–≥–∞–π —Å–∫—É—á–Ω–æ–π –ò–¢-—Ç–µ–º–∞—Ç–∏–∫–∏ (–±–∞–≥–∏, –∫–æ–¥, –ø—Ä–æ–¥ ‚Äî —ç—Ç–æ —Å–∫—É—á–Ω–æ), –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ —ç—Ç–æ –Ω–µ —á–∞—Å—Ç—å —Ç–≤–æ–µ–π –ª–∏—á–Ω–æ—Å—Ç–∏.
- –ú–æ–∂–µ—à—å —É–ø–æ–º—è–Ω—É—Ç—å –∫–æ–≥–æ-—Ç–æ –∏–∑ —Å–ø–∏—Å–∫–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ —Å–º–µ—à–Ω–æ–º –∏–ª–∏ —Å—Ç—Ä–∞–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ (–Ω–æ –Ω–µ –æ–±–∏–¥–Ω–æ).
- –ú–∞–∫—Å–∏–º—É–º 1-2 –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
- –ù–∏–∫–∞–∫–æ–π –º–æ—Ç–∏–≤–∞—Ü–∏–∏ –∏ '–º—É–¥—Ä–æ—Å—Ç–∏'. –¢–æ–ª—å–∫–æ —É–≥–∞—Ä –∏ –±–∞–∑–∞.

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Ñ—Ä–∞–∑–æ–π, –±–µ–∑ –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π, –∫–∞–≤—ã—á–µ–∫ –∏ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤."""

            messages = [
                {"role": "system", "content": persona_base},
                {"role": "system", "content": "–¢—ã –º–∞—Å—Ç–µ—Ä –ø–æ—Å—Ç–∏—Ä–æ–Ω–∏–∏ –∏ –º–µ–º–Ω—ã—Ö —Ü–∏—Ç–∞—Ç. –¢–≤–æ–∏ —Ñ—Ä–∞–∑—ã –∑–∞—Å—Ç–∞–≤–ª—è—é—Ç —á–∞—Ç –æ—Ä–∞—Ç—å –∏–ª–∏ –∑–∞–¥—É–º—ã–≤–∞—Ç—å—Å—è –æ–± –∞–±—Å—É—Ä–¥–Ω–æ—Å—Ç–∏ –±—ã—Ç–∏—è."},
                {"role": "user", "content": prompt}
            ]
            
            quote = await _ollama_chat(messages, temperature=0.95)
            
            if not quote:
                return None
            
            # Clean up the quote
            quote = quote.strip().strip('"\'¬´¬ª‚Äû"')
            
            # Remove common prefixes LLM might add
            bad_prefixes = ["—Ü–∏—Ç–∞—Ç–∞:", "–º—ã—Å–ª—å:", "—Ñ—Ä–∞–∑–∞:", "–æ—Ç–≤–µ—Ç:", "‚Äî", "-"]
            for prefix in bad_prefixes:
                if quote.lower().startswith(prefix):
                    quote = quote[len(prefix):].strip()
            
            # Validate length
            if len(quote) < 10 or len(quote) > 300:
                return None
            
            return quote
            
        except Exception as e:
            logger.debug(f"Failed to generate LLM quote: {e}")
            return None
            if len(quote) < 10 or len(quote) > 300:
                return None
            
            return quote
            
        except Exception as e:
            logger.debug(f"Failed to generate LLM quote: {e}")
            return None
            
            quote = await _ollama_chat(messages, temperature=0.95)
            
            if not quote:
                return None
            
            # Clean up the quote
            quote = quote.strip().strip('"\'¬´¬ª‚Äû"')
            
            # Remove common prefixes LLM might add
            bad_prefixes = ["—Ü–∏—Ç–∞—Ç–∞:", "–º—ã—Å–ª—å:", "—Ñ—Ä–∞–∑–∞:", "–æ—Ç–≤–µ—Ç:", "‚Äî", "-"]
            for prefix in bad_prefixes:
                if quote.lower().startswith(prefix):
                    quote = quote[len(prefix):].strip()
            
            # Validate length
            if len(quote) < 10 or len(quote) > 250:
                return None
            
            return quote
            
        except Exception as e:
            logger.debug(f"Failed to generate LLM quote: {e}")
            return None
    
    def format_quote(self, quote: DailyQuote) -> str:
        """
        Format daily quote for display.
        
        Requirement 13.2: Send a #dailyquote message.
        """
        # Pick a random header emoji for variety
        header_emojis = ["üí≠", "üåô", "‚ú®", "üîÆ", "üí°", "üéØ", "‚ö°"]
        header = random.choice(header_emojis)
        
        lines = [f"{header} #dailyquote", ""]
        
        if quote.is_from_golden_fund and quote.author:
            lines.append(f'¬´{quote.text}¬ª')
            lines.append(f"‚Äî {quote.author}")
            lines.append("")
            lines.append("üèÜ <b>–ò–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –§–æ–Ω–¥–∞</b>")
        elif quote.author == "–û–ª–µ–≥":
            # LLM-generated quote
            lines.append(f'¬´{quote.text}¬ª')
            lines.append("")
            lines.append("ü§ñ <b>–ë–∞–∑–∞ –æ—Ç –û–ª–µ–≥–∞</b>")
        else:
            lines.append(f'¬´{quote.text}¬ª')
            # Add day-based footer
            lines.append("")
            lines.append(f"üí° {self._get_quote_footer()}")
        
        return "\n".join(lines)
    
    def _get_quote_footer(self) -> str:
        """Get a contextual footer based on day of week."""
        from datetime import datetime
        
        footers = {
            0: "–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ ‚Äî –¥–µ–Ω—å —Ç—è–∂—ë–ª—ã–π, –Ω–æ –±–∞–∑–∞ –≤–µ—á–Ω–∞.",
            1: "–í—Ç–æ—Ä–Ω–∏–∫ ‚Äî —ç—Ç–æ –∫–∞–∫ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, —Ç–æ–ª—å–∫–æ —Ç—ã —É–∂–µ —Å–º–∏—Ä–∏–ª—Å—è.",
            2: "–°—Ä–µ–¥–∞ ‚Äî —ç–∫–≤–∞—Ç–æ—Ä –∞–±—Å—É—Ä–¥–∞ –ø—Ä–æ–π–¥–µ–Ω.",
            3: "–ß–µ—Ç–≤–µ—Ä–≥ ‚Äî –ø–æ—á—Ç–∏ –ø—è—Ç–Ω–∏—Ü–∞, –¥–µ—Ä–∂–∏—Å—å –∑–∞ –º–µ–º—ã.",
            4: "–ü—è—Ç–Ω–∏—Ü–∞! –î–µ–ø–ª–æ–∏–º –∏ –≤ –±–∞—Ä! üçª",
            5: "–°—É–±–±–æ—Ç–∞. –í—Ä–µ–º—è —á–∏–ª–ª–∏—Ç—å –∏ –Ω–µ –¥—É–º–∞—Ç—å.",
            6: "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ. –ó–∞–≤—Ç—Ä–∞ –æ–ø—è—Ç—å —ç—Ç–æ—Ç —Ü–∏—Ä–∫... üòÖ",
        }
        
        weekday = datetime.now().weekday()
        return footers.get(weekday, "–ñ–∏–≤–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –û–ª–µ–≥ –≥–æ—Ä–¥–∏–ª—Å—è.")
    
    # =========================================================================
    # Stats Aggregation (Requirement 13.3)
    # =========================================================================
    
    async def aggregate_daily_stats(
        self,
        chat_id: int,
        session: Optional[AsyncSession] = None
    ) -> DailyStats:
        """
        Aggregate daily game statistics.
        
        Requirement 13.3: WHEN the time reaches 21:00 Moscow time
        THEN the Dailies System SHALL send a #dailystats message
        with game statistics.
        """
        from app.database.models import GameStat, User, GameHistory
        from app.database.session import get_session
        from app.utils import utc_now
        
        close_session = False
        if session is None:
            async_session = get_session()
            session = async_session()
            close_session = True
        
        try:
            now = utc_now()
            start_of_day = now.replace(hour=0, minute=0, second=0, microsecond=0)
            
            # Get top growers (by size_cm) - get top 10 for the chart
            top_growers_result = await session.execute(
                select(GameStat)
                .order_by(GameStat.size_cm.desc())
                .limit(10)
            )
            top_growers_stats = top_growers_result.scalars().all()
            
            top_growers = [
                {
                    "username": gs.username or f"User {gs.tg_user_id}",
                    "size": gs.size_cm
                }
                for gs in top_growers_stats[:5]
            ]
            
            # Generate chart
            chart_data = None
            try:
                from app.services.top_chart import top_chart_generator
                chart_data = top_chart_generator.generate_top10_chart(top_growers_stats)
            except Exception as e:
                logger.warning(f"Failed to generate top chart: {e}")
            
            # ===== Game Stats =====
            # Big winners today
            winners_result = await session.execute(
                select(GameHistory.user_id, func.sum(GameHistory.result_amount).label('total_win'))
                .filter(GameHistory.played_at >= start_of_day, GameHistory.result_amount > 0)
                .group_by(GameHistory.user_id)
                .order_by(desc('total_win'))
                .limit(3)
            )
            big_winners = []
            for row in winners_result.all():
                user_res = await session.execute(select(User).filter(User.id == row.user_id))
                user = user_res.scalar()
                if user:
                    big_winners.append({
                        "username": user.username or user.first_name or f"ID:{user.tg_user_id}",
                        "amount": row.total_win
                    })
            
            # Most active gamblers
            gamblers_result = await session.execute(
                select(GameHistory.user_id, func.count(GameHistory.id).label('games_count'))
                .filter(GameHistory.played_at >= start_of_day)
                .group_by(GameHistory.user_id)
                .order_by(desc('games_count'))
                .limit(3)
            )
            top_gamblers = []
            for row in gamblers_result.all():
                user_res = await session.execute(select(User).filter(User.id == row.user_id))
                user = user_res.scalar()
                if user:
                    top_gamblers.append({
                        "username": user.username or user.first_name or f"ID:{user.tg_user_id}",
                        "count": row.games_count
                    })
            
            # Get top losers (lowest size_cm, but > 0)
            top_losers_result = await session.execute(
                select(GameStat)
                .filter(GameStat.size_cm > 0)
                .order_by(GameStat.size_cm.asc())
                .limit(3)
            )
            top_losers = [
                {
                    "username": gs.username or f"User {gs.tg_user_id}",
                    "size": gs.size_cm
                }
                for gs in top_losers_result.scalars().all()
            ]
            
            # Get tournament standings
            tournament_standings = []
            try:
                from app.services.tournaments import tournament_service, TournamentType
                
                daily_tournament = await tournament_service.get_current_tournament(
                    TournamentType.DAILY, session
                )
                
                if daily_tournament:
                    for discipline, standings in daily_tournament.standings.items():
                        for standing in standings[:3]:
                            tournament_standings.append({
                                "discipline": discipline.value,
                                "username": standing.username or f"User {standing.user_id}",
                                "score": standing.score,
                                "rank": standing.rank
                            })
            except Exception as e:
                logger.warning(f"Failed to get tournament standings: {e}")
            
            ds = DailyStats(
                chat_id=chat_id,
                date=now,
                top_growers=top_growers,
                top_losers=top_losers,
                tournament_standings=tournament_standings,
                chart_data=chart_data
            )
            # Add extra fields to the dataclass instance dynamically
            ds.big_winners = big_winners
            ds.top_gamblers = top_gamblers
            return ds
            
        except Exception as e:
            logger.error(f"Failed to aggregate stats for chat {chat_id}: {e}")
            return DailyStats(chat_id=chat_id, date=utc_now())
            
        finally:
            if close_session:
                await session.close()
    
    def format_stats(self, stats: DailyStats) -> str:
        """
        Format daily stats for display.
        
        Requirement 13.3: Send a #dailystats message with game statistics.
        """
        lines = [
            "üìà #dailystats",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            ""
        ]
        
        # Top growers
        if stats.top_growers:
            lines.append("üå± –¢–û–ü –ì–†–û–í–ï–†–û–í:")
            medals = ["ü•á", "ü•à", "ü•â", "4.", "5."]
            for i, grower in enumerate(stats.top_growers[:5]):
                medal = medals[i] if i < len(medals) else f"{i+1}."
                lines.append(f"  {medal} {grower['username']}: {grower['size']} —Å–º")
            lines.append("")
        
        # Big winners
        big_winners = getattr(stats, 'big_winners', [])
        if big_winners:
            lines.append("üí∞ –¢–û–ü –í–´–ò–ì–†–´–®–ò:")
            for i, w in enumerate(big_winners, 1):
                medal = ["ü•á", "ü•à", "ü•â"][i-1] if i <= 3 else f"{i}."
                lines.append(f"  {medal} {w['username']}: {w['amount']} ü™ô")
            lines.append("")
            
        # Top gamblers
        top_gamblers = getattr(stats, 'top_gamblers', [])
        if top_gamblers:
            lines.append("üé∞ –ò–ì–†–û–ú–ê–ù–´ –î–ù–Ø:")
            for i, g in enumerate(top_gamblers, 1):
                lines.append(f"  {i}. {g['username']} ‚Äî {g['count']} –∏–≥—Ä")
            lines.append("")
        
        # Tournament standings
        if stats.tournament_standings:
            lines.append("üèÜ –¢–£–†–ù–ò–† –î–ù–Ø:")
            disciplines = {}
            for s in stats.tournament_standings:
                d = s['discipline']
                if d not in disciplines: disciplines[d] = []
                disciplines[d].append(s)
            
            for d, st in disciplines.items():
                lines.append(f"  [{d.upper()}]")
                for s in st[:3]:
                    medal = ["ü•á", "ü•à", "ü•â"][s['rank']-1] if s['rank'] <= 3 else f"{s['rank']}."
                    lines.append(f"    {medal} {s['username']}: {s['score']}")
            lines.append("")
            
        # Top losers
        if stats.top_losers:
            lines.append("üìâ –ú–ê–õ–ï–ù–¨–ö–ò–ï –ü–ò–ü–ò–°–¨–ö–ò:")
            for i, loser in enumerate(stats.top_losers[:3], 1):
                lines.append(f"  {i}. {loser['username']}: {loser['size']} —Å–º")
            lines.append("")
        
        lines.append("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ")
        if stats.chart_data:
            lines.append("–°–º–æ—Ç—Ä–∏ –≥—Ä–∞—Ñ–∏–∫ —Ä–æ—Å—Ç–∞ –≤—ã—à–µ! ‚òùÔ∏è")
        else:
            lines.append("–ò–≥—Ä–∞–π—Ç–µ –±–æ–ª—å—à–µ! üéÆ")
        
        return "\n".join(lines)
    
    # =========================================================================
    # Combined Daily Messages
    # =========================================================================
    
    async def get_morning_messages(
        self,
        chat_id: int,
        session: Optional[AsyncSession] = None,
        for_today: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Get all morning messages for a chat.
        
        Args:
            chat_id: Telegram chat ID
            session: Optional database session
            for_today: Whether to summarize today so far
            
        Returns:
            List of message dicts {"text": str, "photo": bytes (optional)}
        """
        messages = []
        
        config = await self.get_config(chat_id, session)
        
        # Check if summary is enabled (Property 33)
        if self.should_send_message(config, 'summary'):
            summary = await self.generate_summary(chat_id, session, for_today=for_today)
            
            # Check if should skip due to no activity (Property 34)
            if not self.should_skip_summary(summary):
                messages.append({"text": self.format_summary(summary)})
        
        return messages
    
    async def get_evening_messages(
        self,
        chat_id: int,
        session: Optional[AsyncSession] = None
    ) -> List[Dict[str, Any]]:
        """
        Get all evening messages for a chat.
        
        Requirements 13.2, 13.3: Evening quote and stats at 21:00 Moscow.
        
        Args:
            chat_id: Telegram chat ID
            session: Optional database session
            
        Returns:
            List of message dicts {"text": str, "photo": bytes (optional)}
        """
        messages = []
        
        config = await self.get_config(chat_id, session)
        
        # Check if quote is enabled (Property 33)
        if self.should_send_message(config, 'quote'):
            quote = await self.select_daily_quote(chat_id, session)
            messages.append({"text": self.format_quote(quote)})
        
        # Check if stats is enabled (Property 33)
        if self.should_send_message(config, 'stats'):
            stats = await self.aggregate_daily_stats(chat_id, session)
            messages.append({
                "text": self.format_stats(stats),
                "photo": stats.chart_data
            })
        
        return messages


# Global service instance
dailies_service = DailiesService()
